model:
  target: model.unet.UNet
  params:
    timestep_embed: 16
    size: [64, 64]
    in_channels: 3
    out_channels: 3
    base_hidden_channels: 64
    n_layers: 4
    cross_attention: False
    chan_multiplier: [1, 2, 4, 8]
    inner_layers: [3, 3, 3, 3]
    attention_layers: [False, False, True, False]
    z_dim: 512

encoder:
    target: model.latent_encoder.LatentEncoder
    params:
      in_channels: 3
      base_hidden_channels: 64
      n_layers: 5
      chan_multiplier: [1, 2, 4, 8, 8]
      inner_layers: [3, 3, 3, 3, 3]
      attention_layers: [False, False, True, False, False]
      linear_layers: [1472, 2048, 1024, 512]
      z_dim: 512
      dropout: 0.0

diffusion:
  target: model.diffusion.AutoEncoderGaussianDiffusion
  params:
    image_size: 64
    timesteps: 1000
    loss_type: l2


training:
  batch_size: 128
  learning_rate: 1e-4
  save_every: 10000
  sample_every: 500
  grandient_accumulation_steps: 4
  grad_clip: 1
  ema_decay: 0.995
  epochs: 500
  fp16: True
  scheduler: none



data:
  target: data.ffhq.FFHQDataset
  params:
    root: ./dataset/ffhq-64
