model:
  target: model.unet.UNet
  params:
    timestep_embed: 16
    size: [28, 28]
    in_channels: 1
    out_channels: 1
    base_hidden_channels: 32
    n_layers: 2
    chan_multiplier: [1, 2]
    inner_layers: [2, 2]
    attention_layers: [False, True]
    z_dim: 64

encoder:
    target: model.latent_encoder.LatentEncoder
    params:
      in_channels: 1
      base_hidden_channels: 32
      n_layers: 2
      chan_multiplier: [1,2]
      inner_layers: [1,2]
      attention_layers: [False, True]
      z_dim: 64
      dropout: 0.1

diffusion:
  target: model.diffusion.AutoEncoderGaussianDiffusion
  params:
    image_size: 28
    timesteps: 1000


training:
  optimizer:
    target: torch.optim.AdamW
    params:
      lr: 1e-4
      betas: (0.9, 0.999)
      weight_decay: 0.0001
      amsgrad: False
  scheduler:
    target: None
    params:
  learning_rate: 1e-4
  batch_size: 256
  save_every: 1000
  sample_every: 500
  grandient_accumulation_steps: 1
  grad_clip: 0.1
  ema_decay: 0.995
  fp16: True

data:
  target: data.mnist.MNIST
  params:
    root: /media/lleonard/big_slow_disk/datasets/mnist